{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #1: Titanic Survival Analysis using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"Train_Titanic.csv\")\n",
    "training.head(5)\n",
    "training.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sur = training[training[\"Survived\"] == 1]\n",
    "no_sur = training[training[\"Survived\"] == 0]\n",
    "\n",
    "print('Total = ', len(training))\n",
    "print('Number of passengers who survived =' ,len(sur))\n",
    "print('Number of passengers who didnt survived =' ,len(no_sur))\n",
    "\n",
    "print('% Survived =', 1. * len(sur)/len(training) * 100)\n",
    "print('% Did not Survived =', 1. * len(no_sur)/len(training) * 100)\n",
    "\n",
    "plt.figure(figsize = [6,12])\n",
    "plt.subplot(221)\n",
    "sns.countplot(x = \"Pclass\", data = training)\n",
    "plt.subplot(212)\n",
    "sns.countplot(x = \"Pclass\", hue = \"Survived\", data = training)\n",
    "\n",
    "plt.figure(figsize = [6,12])\n",
    "plt.subplot(221)\n",
    "sns.countplot(x = \"SibSp\", data = training)\n",
    "plt.subplot(212)\n",
    "sns.countplot(x = \"SibSp\", hue = \"Survived\", data = training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(training.isnull(), yticklabels = False, cbar = False, cmap = 'Blues')\n",
    "training.drop('Cabin', axis = 1, inplace = True )\n",
    "print(training)\n",
    "\n",
    "training.drop(['Name', 'Ticket', 'Embarked'], axis = 1, inplace = True)\n",
    "print(training)\n",
    "\n",
    "plt.figure(figsize = (15, 10))\n",
    "sns.boxplot(x = 'Sex', y = 'Age', data = training)\n",
    "\n",
    "def Fill_Age(data):\n",
    "  age = data[0]\n",
    "  sex = data[1]\n",
    "\n",
    "  if pd.isnull(age):\n",
    "    if sex is 'male':\n",
    "      return 29\n",
    "    else:\n",
    "      return 25\n",
    "  else:\n",
    "    return age\n",
    "\n",
    "training['Age'] = training[['Age','Sex']].apply(Fill_Age, axis = 1)\n",
    "sns.heatmap(training.isnull(), yticklabels = False, cbar = False, cmap = 'Blues')\n",
    "\n",
    "training['Age'].hist(bins = 20)\n",
    "\n",
    "training.drop(['PassengerId'], axis = 1, inplace = True)\n",
    "print(training)\n",
    "\n",
    "male = pd.get_dummies(training['Sex'])\n",
    "print(male)\n",
    "\n",
    "training.drop(['Sex'], axis = 1, inplace = True)\n",
    "print(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x = training.drop('Survived', axis = 1).values\n",
    "y = training['Survived'].values    \n",
    "xTrain, yTrain, xTest, yTest = train_test_split(x, y, rest_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clas = LogisticRegression(random_state = 0)\n",
    "clas.fit(xTrain, yTrain)\n",
    "\n",
    "ypred = clas.predict(xTest)\n",
    "print(ypred)\n",
    "\n",
    "cm = confusion_matrix(yTest, ypred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'd')\n",
    "\n",
    "print(classification_report(yTest, ypred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #2: Predict Customer Clicks on Ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training = pd.read_csv('Faceboo_Ada_2.csv', encoding = 'ISO-8859-1')\n",
    "print(training.head(), training.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click = training[training['Clicked'] == 1]\n",
    "no_click = training[training['Clicked'] == 0]\n",
    "print(click, no_click)\n",
    "\n",
    "print('Total = ', len(training))\n",
    "print('Number of customers who clicked', len(click))\n",
    "print('Number of customers who did not clicked', len(no_click))\n",
    "\n",
    "sns.scatterplot(training['Time Spent on Site'], training['Salary'], hue = training[ 'Clicked'])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.boxplot(x = 'Clicked', y = 'Salary', data = training)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.boxplot(x = 'Clicked', y = 'Time Spent on Site', data = training)\n",
    "\n",
    "training[\"Salary\"].hist(bins = 40)\n",
    "training[\"Time Spent on Site\"].hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.drop(['Names', 'emails', 'Country'], axis = 1, inplace = True)\n",
    "print(training)\n",
    "\n",
    "x = training.drop('Clicked', axis = 1).values\n",
    "y = training.drop['Clicked'].values\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clas = LogisticRegression(random_state = 0)\n",
    "clas.fit(xTrain, yTrain)\n",
    "\n",
    "y_pred = clas.predict(xTrain)\n",
    "print(y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "cm = confusion_matrix(yTrain, y_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'd')\n",
    "\n",
    "y_pred_test = clas.predict(xTest)\n",
    "cm = confusion_matrix(yTest, y_pred_test)\n",
    "sns.heatmap(cm, annot = True, fmt = 'd')\n",
    "\n",
    "print(classification_report(yTest, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "x_set, y_set = xTrain, yTrain\n",
    "x1, x2 = np.meshgrid(\n",
    "    np.arange(start = x_set[:, 0].min() - 1, stop = x_set[:,0].max() + 1, step = 0.01),\n",
    "    np.arange(start = x_set[:, 1].min() - 1, stop = x_set[:, 1].max() + 1, step = 0.01))\n",
    "\n",
    "plt.contourf(x1, x2, clas.predict(np.array([x1.ravel(), x2.ravel()]).T).reshape(x1.shape),\n",
    "                alpha = 0.75, cmap = ListedColormap(('magenta', 'blue')))\n",
    "plt.xlim(x1.min(), x1.max())\n",
    "plt.ylim(x2.min(), x2.max())\n",
    "\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(x_set[y_set == j, 0], x_set[y_set == j, 1],\n",
    "                    c = ListedColormap(('magenta', 'blue'))(i), label = j)\n",
    "plt.title(\"Facebook Ad: Customer Click Prediction (Training set)\")\n",
    "plt.xlabel(\"Time Spent on Site\")\n",
    "plt.ylabel(\"Estimated Salary\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "x_set, y_set = xTest, yTest\n",
    "x1, x2 = np.meshgrid(\n",
    "    np.arange(start = x_set[:, 0].min() - 1, stop = x_set[:,0].max() + 1, step = 0.01),\n",
    "    np.arange(start = x_set[:, 1].min() - 1, stop = x_set[:, 1].max() + 1, step = 0.01))\n",
    "\n",
    "plt.contourf(x1, x2, clas.predict(np.array([x1.ravel(), x2.ravel()]).T).reshape(x1.shape),\n",
    "                alpha = 0.75, cmap = ListedColormap(('magenta', 'blue')))\n",
    "plt.xlim(x1.min(), x1.max())\n",
    "plt.ylim(x2.min(), x2.max())\n",
    "\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(x_set[y_set == j, 0], x_set[y_set == j, 1],\n",
    "                    c = ListedColormap(('magenta', 'blue'))(i), label = j)\n",
    "plt.title(\"Facebook Ad: Customer Click Prediction (Test set)\")\n",
    "plt.xlabel(\"Time Spent on Site\")\n",
    "plt.ylabel(\"Estimated Salary\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #3: Breast Cancer Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer, \n",
    "      cancer.keys(),\n",
    "      cancer['DESCR'],\n",
    "      cancer['target_names'],\n",
    "      cancer[\"feature_names\"],\n",
    "      cancer['data'])\n",
    "\n",
    "cancer_df = pd.DataFrame(np.c_[cancer['data'], cancer['target']], \n",
    "                         columns = np.append(cancer['feature_names'], ['target']))\n",
    "print(cancer_df)\n",
    "\n",
    "cancer_df.head(5)\n",
    "cancer_df.tail(5)\n",
    "\n",
    "sns.pairplot(cancer_df, hue = 'target', vars = ['mean radius', 'mean texture', \n",
    "                                                'mean area', 'mean perimeter', 'mean smoothness'])\n",
    "sns.countplot(cancer_df['target'], label = \"Count\")\n",
    "sns.scatterplot(x = \"mean area\", y = \"mean smoothness\", hue = \"target\", data = cancer_df)\n",
    "sns.scatterplot(x = \"mean texture\", y = \"mean radius\", hue = \"target\", data = cancer_df)\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "sns.heatmap(cancer_df.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cancer_df.drop(['target'], axis = 1)\n",
    "y = cancer_df['target']\n",
    "print(x, y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.25)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import metrics, confusion_matrix, classification_report\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(xTrain, yTrain)\n",
    "\n",
    "y_pred = svc_model.predict(xTest)\n",
    "print(y_pred)\n",
    "\n",
    "cm = confusion_matrix(yTest, y_pred)\n",
    "sns.heatmap(cm, annot = True)\n",
    "\n",
    "print(classification_report(yTest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train = xTrain.min()\n",
    "print(min_train)\n",
    "\n",
    "range_train = (xTrain - min_train).max()\n",
    "print(range_train)\n",
    "\n",
    "xTrain_scaled = (xTrain - min_train)/range_train\n",
    "print(xTrain_scaled)\n",
    "\n",
    "y_predict = svc_model.predict(xTrain_scaled)\n",
    "\n",
    "sns.scatterplot(x = xTrain['mean area'], y = xTrain['mean smoothness'], hue = yTrain)\n",
    "sns.scatterplot(x = xTrain_scaled['mean area'], y = xTrain_scaled['mean smoothness'], hue = yTrain)\n",
    "\n",
    "min_test = xTest.min()\n",
    "print(min_test)\n",
    "\n",
    "range_test = (xTest - min_test).max()\n",
    "print(range_test)\n",
    "\n",
    "xTest_scaled = (xTest - min_test)/range_test\n",
    "print(xTest_scaled)\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(xTrain_scaled, yTrain)\n",
    "\n",
    "y_predict_test = svc_model.predict(xTest_scaled)\n",
    "cm = confusion_matrix(yTest, y_predict_test)\n",
    "\n",
    "sns.heatmap(cm, annot = True, fmt = \"d\")\n",
    "print(classification_report(yTest, y_predict))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #4: Bank Customer Retirement Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df = pd.read_csv('Bank_Customer_retirement.csv')\n",
    "print(bank_df,\n",
    "      bank_df.keys(),\n",
    "      bank_df.head(10))\n",
    "\n",
    "sns.pairplot(bank_df, hue = 'Retire', vars = ['Age', '401K Savings'])\n",
    "sns.countplot(bank_df['Retire'], label = \"Retirement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.drop(['Customer ID'], axis = 1, inplace = True)\n",
    "print(bank_df)\n",
    "\n",
    "x = bank_df.drop(['Retire'], axis = 1)\n",
    "print(x)\n",
    "\n",
    "y = bank_df['Retire']\n",
    "print(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 5)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "svc_model = SVC()\n",
    "svc_model.fit(xTrain, yTrain)\n",
    "\n",
    "y_predict = svc_model.predict(xTest)\n",
    "cm = confusion_matrix(yTest, y_predict)\n",
    "\n",
    "sns.heatmap(cm, annot = True)\n",
    "print(classification_report(yTest, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train = xTrain.min()\n",
    "print(min_train)\n",
    "\n",
    "range_train = (xTrain - min_train).max()\n",
    "print(range_train)\n",
    "\n",
    "xTrain_scaled = (xTrain - min_train)/range_train\n",
    "print(xTrain_scaled)\n",
    "\n",
    "sns.scatterplot(x = xTrain['Age'], y = xTrain['401K Savings'], hue = yTrain)\n",
    "sns.scatterplot(x = xTrain_scaled['Age'], y = xTrain_scaled['401K Savings'], hue = yTrain)\n",
    "\n",
    "min_test = xTest.min()\n",
    "print(min_test)\n",
    "\n",
    "range_test = (xTest - min_test).max()\n",
    "print(range_test)\n",
    "\n",
    "xTest_scaled = (xTest - min_test)/range_test\n",
    "print(xTest_scaled)\n",
    "\n",
    "sns.scatterplot(x = xTest['Age'], y = xTest['401K Savings'], hue = yTest)\n",
    "sns.scatterplot(x = xTest_scaled['Age'], y = xTest_scaled['401K Savings'], hue = yTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf']}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 4)\n",
    "grid.fit(xTrain_scaled, yTrain)\n",
    "\n",
    "grid.best_params_\n",
    "grid_predict = grid.predict(xTrain_scaled)\n",
    "cm = confusion_matrix(yTest, grid_predict)\n",
    "sns.heatmap(cm, annot = True)\n",
    "print(classification_report(yTest, grid_predict))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #5: T-shirt Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tshirt = pd.read_csv('Tshirt_Sizing_Dataset.csv')\n",
    "print(tshirt.head(3))\n",
    "print(tshirt.tails(3))\n",
    "print(tshirt.iloc[:, 0:2].values)\n",
    "\n",
    "y = tshirt.iloc[:, 2].values\n",
    "print(y)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "print(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.25)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(xTrain, yTrain)\n",
    "y_pred = classifier.predict(xTest)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(yTest, y_pred)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colorbar import ListedColormap\n",
    "x_grid, y_grid = xTest, yTest\n",
    "x1, x2 = np.meshgrid(np.arange(start = x_grid[:, 0].min() - 1,stop = x_grid[:, 0].max() + 1, step = 0.01), \n",
    "                     np.arange(start = x_grid[:, 1].min() - 1,stop = x_grid[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(x1, x2, classifier.predict(np.array([x1.ravel(), x2.ravel()]).T).reshape(x1.shape), alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n",
    "plt.xlim(x1.min(), x1.max())\n",
    "plt.ylim(x2.min(), x2.max())\n",
    "for i, j in enumerate(np.unique(y_grid)):\n",
    "    plt.scatter(x_grid[y_grid == j, 0], x_grid[y_grid == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "\n",
    "plt.title('Testing dataset')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend()\n",
    "plt.show()                 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #6: IRIS Plant Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris_df = pd.read_csv('iris.csv')\n",
    "print(iris_df)\n",
    "\n",
    "iris_df.head(10)\n",
    "iris_df.tail(10)\n",
    "\n",
    "sns.scatterplot(x = 'SepalLength', y = 'SepalWidth', hue = 'Species', data = iris_df)\n",
    "sns.scatterplot(x = 'PetalLengthCm', y = 'PetalWidthCm', hue = 'Species', data = iris_df)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.violinplot(x = 'Species', y = 'PetalLengthCm', data = iris_df)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.violinplot(x = 'Species', y = 'PetalWidthCm', data = iris_df)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.violinplot(x = 'Species', y = 'SepalLengthCm', data = iris_df)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.violinplot(x = 'Species', y = 'SepalWidthCm', data = iris_df)\n",
    "\n",
    "sns.pairplot(iris_df, hue = \"Species\")\n",
    "sns.heatmap(iris_df.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris_df.drop(['Species'], axis = 1)\n",
    "print(x)\n",
    "\n",
    "y = iris_df['Species']\n",
    "print(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.35)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(xTrain, yTrain)\n",
    "y_pred = classifier.predict(xTest)\n",
    "\n",
    "cm = confusion_matrix(yTest, y_pred)\n",
    "sns.heatmap(cm, annot = True)\n",
    "print(classification_report(yTest, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #7: Amazon Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alexa = pd.read_csv('amazon_alexa.tsv', sep = '\\t')\n",
    "print(df_alexa.head(5))\n",
    "print(df_alexa.tail(5))\n",
    "print(df_alexa.keys())\n",
    "\n",
    "df_alexa['verified_reviews']\n",
    "df_alexa['feedback']\n",
    "df_alexa['variation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df_alexa[df_alexa['feedback'] == 1]\n",
    "negative = df_alexa[df_alexa['feedback'] == 0]\n",
    "print(positive, negative)\n",
    "\n",
    "sns.countplot(df_alexa['feedback'], label = \"Count\")\n",
    "sns.countplot(x = 'rating', data = df_alexa)\n",
    "df_alexa['rating'].hist(bins = 5)\n",
    "\n",
    "plt.figure(figsize = (40, 15))\n",
    "sns.barplot(x = 'variation', y = 'rating', data = df_alexa, palette = 'deep')\n",
    "\n",
    "df_alexa = df_alexa.drop(['date', 'rating'], axis = 1)\n",
    "variation_dummies = pd.get_dummies(df_alexa['variation'], drop_first = True)\n",
    "print(df_alexa, variation_dummies)\n",
    "\n",
    "df_alexa.drop(['variation'], axis = 1, inplace = True)\n",
    "print(df_alexa)\n",
    "\n",
    "df_alexa = pd.concat([df_alexa, variation_dummies], axis = 1)\n",
    "print(df_alexa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "alexa_countvectorizer = vectorizer.fit_transform(df_alexa['verified_reviews'])\n",
    "print(alexa_countvectorizer.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(alexa_countvectorizer.toarray())\n",
    "\n",
    "df_alexa.drop(['verified_reviews'], axis = 1, inplace = True)\n",
    "print(df_alexa)\n",
    "\n",
    "encoded_reviews = pd.DataFrame(alexa_countvectorizer.toarray())\n",
    "df_alexa = pd.concat([df_alexa, encoded_reviews], axis = 1)\n",
    "\n",
    "x = df_alexa.drop(['feedback'], axis = 1)\n",
    "y = df_alexa['feedback']\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.3, random_state = 5)\n",
    "print(xTrain).shape, print(xTest).shape, print(yTrain).shape, print(yTest).shape\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "RandomForestClassifier = RandomForestClassifier(n_estimators = 50, criterion = 'entropy')\n",
    "\n",
    "RandomForestClassifier.fit(xTrain, yTrain)\n",
    "y_pred = RandomForestClassifier.predict(xTrain)\n",
    "cm = confusion_matrix(y_pred, yTrain)\n",
    "\n",
    "sns.heatmap(cm, annot = True)\n",
    "print(classification_report(y_pred, yTrain))\n",
    "\n",
    "y_pred_test = RandomForestClassifier.predict(xTest)\n",
    "sns.heatmap(cm, annot = True)\n",
    "\n",
    "df_alexa = pd.concat([df_alexa, pd.DataFrame(alexa_countvectorizer.toarray())], axis = 1)\n",
    "print(df_alexa)\n",
    "\n",
    "df_alexa['length'] = df_alexa['verified_reviews'].apply(len)\n",
    "print(df_alexa)\n",
    "\n",
    "x = df_alexa.drop(['rating', 'date', 'variation', 'verified_reviews', 'feedback'], axis = 1)\n",
    "print(x)\n",
    "\n",
    "y = df_alexa['feedback']\n",
    "print(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.3, random_state = 5)\n",
    "print(xTrain).shape, print(xTest).shape, print(yTrain).shape, print(yTest).shape\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "RandomForestClassifier = RandomForestClassifier(n_estimators = 50, criterion = 'entropy')\n",
    "\n",
    "RandomForestClassifier.fit(xTrain, yTrain)\n",
    "y_pred = RandomForestClassifier.predict(xTrain)\n",
    "cm = confusion_matrix(y_pred, yTrain)\n",
    "\n",
    "sns.heatmap(cm, annot = True)\n",
    "print(classification_report(y_pred, yTrain))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #8: Kyphosis Disesae Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kyphosis_df = pd.read_csv('kyphosis.csv')\n",
    "print(kyphosis_df.head(10))\n",
    "print(kyphosis_df.tail(10))\n",
    "print(kyphosis_df.describe())\n",
    "print(kyphosis_df.info())\n",
    "\n",
    "sns.countplot(kyphosis_df['Kyphosis'], label = \"count\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, ONeHotEndcoder\n",
    "labelencoder_y = LabelEncoder()\n",
    "kyphosis_df['Kyphosis'] = labelencoder_y.fit_transform(kyphosis_df['Kyphosis'])\n",
    "print(kyphosis_df)\n",
    "\n",
    "kyphosis_True = kyphosis_df[kyphosis_df['Kyphosis'] == 0]\n",
    "print(kyphosis_True)\n",
    "\n",
    "kyphosis_False= kyphosis_df[kyphosis_df['Kyphosis'] == 1]\n",
    "print(kyphosis_False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
